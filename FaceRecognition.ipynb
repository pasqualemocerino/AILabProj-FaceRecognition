{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FaceRecognition.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMKpKhckYniOMG6NV3ykgNi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Face Recognition\n","Face Recogniton is a form of biometrics, the science which deals with the automated recognition of individuals based on biological and behavioral characteristics. It is included in physiological or static biometrics, based on data derived from the measurement of a part of a person's anatomy.\n","The main purpose is the authentication of the subject, which follows identification and is based on proving the previously declared identity.\n","We will later discuss about the advantages and disadvantages of this mechanism, analysing the requirements for an ideal biometric identifier:\n","1. Universality\n","2. Uniqueness\n","3. Performance\n","4. Collectability\n","5. Acceptability\n","\n","Face Recognition or Face Identification is: given the picture of the face of an unknown person, identify the name of the person by referring to a gallery of previously seen pictures of identified persons.\n"],"metadata":{"id":"ey0_FL5hqG0x"}},{"cell_type":"markdown","source":["###About the dataset\n","Labeled Faces in the Wild (LFW) is an image dataset containing face photographs, collected especially for studying the problem of unconstrained face recognition. It includes over 13,000 images of faces collected from across the web. Here are key aspects of these images:\n","\n","Each face in this data set was labeled with the personâ€™s name in the image.\n","1680 of the photographed persons distinctly appear in two or more photos in the data set.\n","The faces in these images were detected by the Viola-Jones face detector (Paul Viola and Michael Jones, 2001).\n","\n","LFW includes four different sets of images, including the original and three types of aligned images that can be used to test algorithms under different conditions. For alignment, the dataset uses funneled images (ICCV 2007), LFW-a, and deep funneled images (NIPS 2012). Deep funneled and LFW-a images produce superior results for most face verification algorithms over the funneled images and the original images.\n","\n","Face Recognition is a task typically performed on the output of a model trained to perform Face Detection. The most popular model for Face Detection is called Viola-Jones and is implemented in the OpenCV library. The LFW faces were extracted by this face detector from various online websites."],"metadata":{"id":"G4qDuODxas12"}},{"cell_type":"markdown","source":["###Purpose\n","Our first purpose is to train an image classifier to work on a dataset of well-known faces of famous people. Then we will make the neural network recognize further faces extending the dataset with new measurements linked to proper identity labels. The final objective is to make an app which recognize human faces after collecting data."],"metadata":{"id":"dIn508Tuslbr"}},{"cell_type":"markdown","source":["#Schedule\n","1. Exploratory Data Analysis \n","2. Define the relevant metrics to be used\n","3. Train a first baseline algorithm as a reference\n","4. Prepare data where needed\n","5. Design experiments and define hyperparameters \n","6. Repeat until performance on the test set is acceptable"],"metadata":{"id":"sEvdbZKHugMA"}},{"cell_type":"markdown","source":["###Exploratory Data Analysis \n","* Regression or Classification?\n","We are obiouvsly dealing with a problem of classification of faces regarding their labels.\n","\n","* What is the target variable?\n","The target variable of a dataset is the feature of a dataset about which you want to gain a deeper understanding. A supervised machine learning algorithm uses historical data to learn patterns and uncover relationships between other features of your dataset and the target.\n","Targets are labeled in the dataset and consists in the identities associated with famous faces.\n","\n","* Is the data unbalanced?\n","* What are the features? Correlation, ranges, variances, NaN, errors...\n","* Plot to make findings clearer\n"],"metadata":{"id":"TvvJx6stvGhh"}},{"cell_type":"markdown","source":["###Define the relevant metrics to be used"],"metadata":{"id":"Sdcg9o0yvhsv"}},{"cell_type":"markdown","source":["###Train a first baseline algorithm as a reference\n","For classification, train basic models as the one-class-classifier and the basic logistic regression with all the features."],"metadata":{"id":"LcjtmLzmvyrx"}},{"cell_type":"markdown","source":["###Prepare data where needed\n","* Cleaning\n","* Normalization \n","* Shuffling and train, test and validation set construction (check the statistical properties of the splits)"],"metadata":{"id":"sG0M4c5gwGM3"}},{"cell_type":"markdown","source":["###Design experiments and define hyperparameters"],"metadata":{"id":"rSDQjhFawW7g"}},{"cell_type":"markdown","source":["###Repeat until performance on the test set is acceptable \n","* Train model and cross validate hyperparameters until acceptable performance on training set is achieved\n","* Test best hyperparameter model and check if there is overfitting or underfitting\n","\n"],"metadata":{"id":"c1OWBFe3wcZd"}},{"cell_type":"markdown","source":["# Training an image classifier\n","We will do the following steps in order:\n","1. Load and normalize the training test datasets using ``torchvision``\n","2. Define a Convolutional Neural Network\n","3. Define a loss function and an optimizer\n","4. Train the network on the training data \n","5. Test the network on the test data "],"metadata":{"id":"M3rWL-jbKy_j"}},{"cell_type":"code","source":["%matplotlib inline"],"metadata":{"id":"Ysk2HAPTK_P3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch \n","import torchvision\n","import torchvision.transforms as transforms"],"metadata":{"id":"ETFJfd2uLwBB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###1. Load and normalize training test datasets\n","(The output of torchvision datasets are PILImage of range [0,1]. We transform them to Tensors of normalized range [-1,1].)"],"metadata":{"id":"czmsILhAL8Bg"}},{"cell_type":"code","source":["#Training hyperparameters\n","INIT_LR = 0.001\n","BATCH_SIZE = 64\n","EPOCHS = 10\n","\n","#Train and val split\n","TRAIN_SPLIT = 0.75\n","VAL_SPLIT = 1 - TRAIN_SPLIT\n","\n","#Setting the device to train the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","#Loading the dataset\n","print(\"[INFO] Loading the LFW dataset...\")\n","#transform = transforms.Compose(\n","#    [transforms.ToTensor(),\n","#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","#trainset = \n","#trainloader =\n","\n","#testset = \n","#testloader =\n","\n","\n"],"metadata":{"id":"yAFfYs_eMQFJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656774478570,"user_tz":-120,"elapsed":230,"user":{"displayName":"pasquale mocerino","userId":"10030967677825155784"}},"outputId":"8fc46caf-4631-4b5a-f354-831af994b28a"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Loading the LFW dataset...\n"]}]},{"cell_type":"markdown","source":["###2. Define a Convolutional Neural Network \n","The CNN is created from scratch to take 3-channel images."],"metadata":{"id":"qvw_zhycNTW-"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvNet(nn.Module): \n","    def _init_(self):\n","      super(ConvNet, self)._init_()\n","      self.conv1 = nn.Conv2d(...)\n","      self.pool = nn.MaxPool2d(....)\n","      self.conv2 = nn.Conv2d(...)\n","      self.fc1 = nn.Linear(...)\n","      self.fc2 = nn.Linear(...)\n","\n","    def forward(self, x):\n","      x = self.pool(F.relu(self.conv1(x)))\n","      x = self.pool(F.relu(self.conv2(x)))\n","      x = x.view(....)\n","      x = F.relu(self.fc1(x))\n","      x = F.relu(self.fc2(x))\n","      x = self.fc3(x)\n","      return x\n","\n","net = ConvNet()"],"metadata":{"id":"09Zh1sPQNgqV","colab":{"base_uri":"https://localhost:8080/","height":133},"executionInfo":{"status":"error","timestamp":1656686241786,"user_tz":-120,"elapsed":280,"user":{"displayName":"pasquale mocerino","userId":"10030967677825155784"}},"outputId":"fc6b24ce-dfdb-490f-de48-6e03d0949899"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-fba461b09839>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    self.pool = nn.MaxPool2d(....)\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","source":["###3. Define a loss function and an optimizer\n","We use a Classification Cross-Entropy loss and SGD with momentum."],"metadata":{"id":"Gn_M6vmHOvbW"}},{"cell_type":"code","source":["import torch.optim as optim \n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)"],"metadata":{"id":"WYFJRsPIPL97","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"error","timestamp":1656686246303,"user_tz":-120,"elapsed":270,"user":{"displayName":"pasquale mocerino","userId":"10030967677825155784"}},"outputId":"b68c2295-a2f9-4675-8c77-9dc6c3661139"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-5f7279a56a33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}]},{"cell_type":"markdown","source":["###4. Train the network on the training data\n","We have to loop over our data iterator and feed the inputs to the network and optimize."],"metadata":{"id":"zPOvqV_MPYmT"}},{"cell_type":"code","source":["for epoch in range(2):\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","      inputs, labels = data\n","\n","      optimizer.zero_grad()\n","\n","      outputs = net(inputs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","      running_loss += loss.item()\n","      if i % 2000 == 1999:\n","        print('[%d, %5d] loss: %.3f' %\n","              (epoch + 1, i + 1, running_loss / 2000))\n","        running_loss = 0.0\n","print('Finished Training')"],"metadata":{"id":"izcndweRPyH9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###5. Test the network on the test data \n","Check if the network has learnt anything at all."],"metadata":{"id":"ZZbgsOQyQ_lU"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def imshow(img):\n","  img = img/2 + 0.5\n","  npimg = img.numpy()\n","  plt.imshow(np.transpose(npimg, (1,2,0)))\n","\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","\n","imshow(torchvision.utils.make_grid(images))\n","print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"metadata":{"id":"CoZ0xYSMRY07"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataiter = iter(testloader)\n","images, labels = dataiter.next() \n","\n","imshow(torchvision.utils.make_grid(images))\n","print('GroundTruth'.join('%5s' % classes[labels[j]] for j in range(4)))"],"metadata":{"id":"B9OOuuXLSDU5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now let's see what the neural network thinks these examples above are:"],"metadata":{"id":"EEe6rII1SSMK"}},{"cell_type":"code","source":["outputs = net(images)"],"metadata":{"id":"95_zrgOxSY-G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_, predicted = torch.max(outputs, 1)\n","\n","print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"],"metadata":{"id":"wwbQ_09MSdW5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's now check how the network performs on the whole testset."],"metadata":{"id":"6FCh0khnSut0"}},{"cell_type":"code","source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","  for data in testloader:\n","    images, labels = data\n","    outputs = net(images)\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum.item()\n","\n","print('Accuracy of the network on the ----- test images: %d %%' % (correct/total*100))"],"metadata":{"id":"9nopOTz2S3RS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check what are the classes that performed well, and the ones that did not performed well."],"metadata":{"id":"XpPYzRdQTi_S"}},{"cell_type":"code","source":["class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","with torch.no_grad():\n","  for data in testloader:\n","    images, labels = data \n","    outputs = net(images)\n","    _, predicted = torch.max(outputs, 1)\n","    c = (predicted == labels).squeeze()\n","    for i in range(4):\n","      label = labels[i]\n","      class_correct[label] += c[i].item()\n","      class_total[label] += 1 \n","\n","for i in range(10):\n","  print('Accuracy of %5s : %2d %%' % (\n","      classes[i], 100 * class_correct[i] / class_total[i]\n","  ))"],"metadata":{"id":"JIauIn0gTo3u"},"execution_count":null,"outputs":[]}]}